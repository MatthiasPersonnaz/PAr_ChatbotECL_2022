{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-8q8rRRWcp6"
   },
   "source": [
    "# TensorFlow Autoencodeur avec attention pour le PAr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpySVYWJhxaV"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Moi j'ai installé tf addons par `pip install tensorflow-addons==0.13.0` (ET NON PAS `conda install -c esri tensorflow-addons`). Voir les compatibilités [sur le github de tensorflow_addons](https://github.com/tensorflow/addons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_kxfdP4hJUPB"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:36:06) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii_vg-XNXTil"
   },
   "source": [
    "# Step 1: Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PvRnGWnvXm6l"
   },
   "outputs": [],
   "source": [
    "path_reglement_scol  = './word2vec_docs_scol_traités/corpus.txt'\n",
    "path_questions_scol  = './word2vec_docs_scol_traités/toutes-les-questions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFKB2c_tX4wU"
   },
   "source": [
    "# Step 2: Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as regex\n",
    "# acquisition du texte\n",
    "reglement_scol = io.open(path_reglement_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "questions_scol = io.open(path_questions_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "texte = reglement_scol + ' ' + questions_scol\n",
    "texte = regex.sub(\"\\n\", \" \", texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée d'abord une liste de phrases dont chaque mot est séparé par un espace. On a besoin de `spacy` pour découper correctement les mots en français d'abord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases parsées par NLTK\n",
      "phrases tokénisées par spacy\n",
      "phrases découpées en tokens puis refusionnées\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "phrases = nltk.tokenize.sent_tokenize(texte, language='french')\n",
    "print('phrases parsées par NLTK')\n",
    "phrasesTokeniseesSpacy = [nlp(s) for s in phrases]\n",
    "print('phrases tokénisées par spacy')\n",
    "phrasesSpacy = [' '.join([token.text.lower() for token in doc]) for doc in phrasesTokeniseesSpacy]\n",
    "print('phrases découpées en tokens puis refusionnées')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les listes inutiles désormais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del phrasesTokeniseesSpacy\n",
    "del phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un tokéniseur adapté à notre vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters='')\n",
    "# créer un tokenizer adapté à tout le vocabulaire des phrases\n",
    "tokenizer.fit_on_texts(phrasesSpacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer les tenseurs pour toutes les phrases et padder le tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "le règlement de scolarité présente les modalités d' admission à l' école centrale de lyon , les objectifs et les modalités de l' évaluation des connaissances et des compétences de la formation ingénieur , les modalités de diversification de cette formation et les conditions d' obtention des diplômes de l' école centrale de lyon , hors diplômes de master co-accrédités et diplôme d' ingénieur energie en alternance . [8, 131, 1, 59, 860, 4, 102, 6, 175, 9, 3, 25, 46, 1, 43, 10, 4, 861, 16, 4, 102, 1, 3, 77, 12, 90, 16, 12, 104, 1, 5, 42, 88, 10, 4, 102, 1, 1565, 1, 166, 42, 16, 4, 285, 6, 214, 12, 85, 1, 3, 25, 46, 1, 43, 10, 390, 85, 1, 247, 1189, 16, 22, 6, 88, 1190, 18, 615, 13]\n"
     ]
    }
   ],
   "source": [
    "tensor_sentences = tokenizer.texts_to_sequences(phrasesSpacy)\n",
    "print(type(tensor_sentences))\n",
    "print(phrasesSpacy[0],tensor_sentences[0])\n",
    "# enfin on padd le tout pour pouvoir l'utiliser dans un réseau de neurones\n",
    "tensor_sentences = tf.keras.preprocessing.sequence.pad_sequences(tensor_sentences,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 ----> comment\n",
      "5 ----> la\n",
      "38 ----> mobilité\n",
      "211 ----> est-elle\n",
      "1564 ----> vérifiée\n",
      "15 ----> pour\n",
      "4 ----> les\n",
      "97 ----> doubles\n",
      "85 ----> diplômes\n",
      "18 ----> en\n",
      "80 ----> france\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "# Fonction qui convertit un mot en son représentant entier\n",
    "def convert(tokenizer, tensor):\n",
    "    for t in tensor: # t est un entier élément du tenseur\n",
    "        if t != 0:\n",
    "            print (\"%d ----> %s\" % (t, tokenizer.index_word[t]))\n",
    "convert(tokenizer, tensor_sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prepare the DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizer.index_word` est un dictionnaire dont les clés sont des entiers et les valeurs sont des struings (mots du vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:\n",
      "<class 'numpy.ndarray'>\n",
      "(2201, 347)\n",
      "tokenizer:\n",
      "<class 'keras_preprocessing.text.Tokenizer'>\n",
      "<class 'dict'>\n",
      "nombre de données: 2201\n",
      "longueur max phrases en mots: 347\n",
      "taille du vocabulaire: 2555\n",
      "dimension de l'embedding: 16\n"
     ]
    }
   ],
   "source": [
    "print('tensor:')\n",
    "print(type(tensor_sentences))\n",
    "print(np.shape(tensor_sentences))\n",
    "tensor_sentences[0]\n",
    "print(\"tokenizer:\")\n",
    "print(type(tokenizer))\n",
    "print(type(tokenizer.index_word))\n",
    "\n",
    "vocab_inp_size = len(tokenizer.word_index)\n",
    "n_data,max_length = tensor_sentences.shape\n",
    "embedding_dim = 16\n",
    "\n",
    "print(f\"nombre de données: {n_data}\\nlongueur max phrases en mots: {max_length}\\ntaille du vocabulaire: {vocab_inp_size}\\ndimension de l'embedding: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Split the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "1760 1760 441 441\n",
      "28 ----> que\n",
      "32 ----> peut\n",
      "553 ----> offrir\n",
      "7 ----> un\n",
      "503 ----> congé\n",
      "204 ----> sabbatique\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and validation sets using an 80/20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(tensor_sentences, tensor_sentences, test_size=0.2)\n",
    "\n",
    "print(type(input_tensor_train), type(target_tensor_train))\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "\n",
    "# on observe ce qu'il y a dans ces données: si on rééxécute ça change, c'est parce qu'il y a un shuffle aléatoire\n",
    "convert(tokenizer, input_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "# Step 5: create Encoder and Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "# Encoder class\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        \n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x)\n",
    "        return output, state\n",
    "        # hidden state shape == (batch_size, hidden size)\n",
    "        # output       shape == (batch_size, max_len, hidden size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder class\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "\n",
    "\n",
    "    def call(self, enc_output):\n",
    "        attention_outputs, attention_scores = tf.keras.layers.Attention()([enc_output, enc_hidden], return_attention_scores=True)\n",
    "        context = attention_outputs * enc_output\n",
    "        return context,attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the encoder class to check the shapes of the encoder output and hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "60gSVh05Jl6l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Input        shape: (batch_size, timesteps)                (6, 10)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"encoder_1\" (type Encoder).\n\n'Encoder' object has no attribute 'embedding'\n\nCall arguments received:\n  • x=tf.Tensor(shape=(6, 10), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5388/1426362852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Encoder Input        shape: (batch_size, timesteps)                {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Encoder Output       shape: (batch_size, sequence_length, units)   {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5388/119915997.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling layer \"encoder_1\" (type Encoder).\n\n'Encoder' object has no attribute 'embedding'\n\nCall arguments received:\n  • x=tf.Tensor(shape=(6, 10), dtype=int32)"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, 128)\n",
    "\n",
    "enc_in = tf.random.uniform(\n",
    "    (6,10),\n",
    "    minval=0,\n",
    "    maxval=60,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=\"dummy_input_encoder\"\n",
    ")\n",
    "\n",
    "\n",
    "print('Encoder Input        shape: (batch_size, timesteps)                {}'.format(enc_in.shape))\n",
    "enc_output, enc_hidden = encoder(enc_in)\n",
    "\n",
    "print('Encoder Output       shape: (batch_size, sequence_length, units)   {}'.format(enc_output.shape))\n",
    "print('Encoder Hidden_state shape: (batch_size, units)                    {}'.format(enc_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, dimension_embedding, vocab_inp_size, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = 128\n",
    "        self.encoder = Encoder(vocab_inp_size, embedding_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc_output,_ = self.encoder(inputs)\n",
    "        out_dec = self.decoder(enc_output)\n",
    "\n",
    "        return out_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([6, 10]), TensorShape([6, 10, 128]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "autoenc = Autoencoder(16,vocab_inp_size,128)\n",
    "autoenc.compile(optimizer='Adam', loss=tf.losses.MeanSquaredError(), metrics = [\"accuracy\"]) # losses.MeanSquaredError() losses.CosineSimilarity()\n",
    "autoenc.build(input_shape=input_tensor_train.shape)\n",
    "\n",
    "\n",
    "enc_in.shape, autoenc(enc_in).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"encoder_15\" (type Encoder).\n\nin user code:\n\n    File \"C:\\Users\\matth\\AppData\\Local\\Temp/ipykernel_13788/546019233.py\", line 18, in call  *\n        output, state = self.gru(x)\n    File \"C:\\Users\\matth\\.conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 679, in __call__  **\n        return super(RNN, self).__call__(inputs, **kwargs)\n    File \"C:\\Users\\matth\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\matth\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Input 0 of layer \"gru_15\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 347, 16, 16)\n\n\nCall arguments received:\n  • x=tf.Tensor(shape=(None, 347, 16), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13788/3561964662.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mout_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mout_dec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_enc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfunc_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_dec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"encoder_15\" (type Encoder).\n\nin user code:\n\n    File \"C:\\Users\\matth\\AppData\\Local\\Temp/ipykernel_13788/546019233.py\", line 18, in call  *\n        output, state = self.gru(x)\n    File \"C:\\Users\\matth\\.conda\\envs\\tf\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 679, in __call__  **\n        return super(RNN, self).__call__(inputs, **kwargs)\n    File \"C:\\Users\\matth\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\matth\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Input 0 of layer \"gru_15\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 347, 16, 16)\n\n\nCall arguments received:\n  • x=tf.Tensor(shape=(None, 347, 16), dtype=float32)"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, latent_dim)\n",
    "decoder = Decoder(latent_dim)\n",
    "\n",
    "input = tf.keras.Input(shape=(max_length,embedding_dim))\n",
    "out_enc = encoder(input)\n",
    "out_dec = decoder(out_enc)\n",
    "func_model = tf.keras.Model(inputs=input, outputs=out_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "networks_seq2seq_nmt.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
