{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-8q8rRRWcp6"
   },
   "source": [
    "# TensorFlow Autoencodeur avec attention pour le PAr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpySVYWJhxaV"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Moi j'ai installé tf addons par `pip install tensorflow-addons==0.13.0` (ET NON PAS `conda install -c esri tensorflow-addons`). Voir les compatibilités [sur le github de tensorflow_addons](https://github.com/tensorflow/addons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_kxfdP4hJUPB"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:36:06) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii_vg-XNXTil"
   },
   "source": [
    "# Step 1: Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PvRnGWnvXm6l"
   },
   "outputs": [],
   "source": [
    "path_reglement_scol  = './word2vec_docs_scol_traités/corpus.txt'\n",
    "path_questions_scol  = './word2vec_docs_scol_traités/toutes-les-questions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFKB2c_tX4wU"
   },
   "source": [
    "# Step 2: Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as regex\n",
    "# acquisition du texte\n",
    "reglement_scol = io.open(path_reglement_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "questions_scol = io.open(path_questions_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "texte = reglement_scol + ' ' + questions_scol\n",
    "texte = regex.sub(\"\\n\", \" \", texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée d'abord une liste de phrases dont chaque mot est séparé par un espace. On a besoin de `spacy` pour découper correctement les mots en français d'abord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases parsées par NLTK\n",
      "phrases tokénisées par spacy\n",
      "phrases découpées en tokens puis refusionnées\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "phrases = nltk.tokenize.sent_tokenize(texte, language='french')\n",
    "print('phrases parsées par NLTK')\n",
    "phrasesTokeniseesSpacy = [nlp(s) for s in phrases]\n",
    "print('phrases tokénisées par spacy')\n",
    "phrasesSpacy = [' '.join([token.text.lower() for token in doc]) for doc in phrasesTokeniseesSpacy]\n",
    "print('phrases découpées en tokens puis refusionnées')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les listes inutiles désormais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del phrasesTokeniseesSpacy\n",
    "del phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un tokéniseur adapté à notre vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters='')\n",
    "# créer un tokenizer adapté à tout le vocabulaire des phrases\n",
    "tokenizer.fit_on_texts(phrasesSpacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer les tenseurs pour toutes les phrases et padder le tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "le règlement de scolarité présente les modalités d' admission à l' école centrale de lyon , les objectifs et les modalités de l' évaluation des connaissances et des compétences de la formation ingénieur , les modalités de diversification de cette formation et les conditions d' obtention des diplômes de l' école centrale de lyon , hors diplômes de master co-accrédités et diplôme d' ingénieur energie en alternance . [8, 131, 1, 59, 860, 4, 102, 6, 175, 9, 3, 25, 46, 1, 43, 10, 4, 861, 16, 4, 102, 1, 3, 77, 12, 90, 16, 12, 104, 1, 5, 42, 88, 10, 4, 102, 1, 1565, 1, 166, 42, 16, 4, 285, 6, 214, 12, 85, 1, 3, 25, 46, 1, 43, 10, 390, 85, 1, 247, 1189, 16, 22, 6, 88, 1190, 18, 615, 13]\n"
     ]
    }
   ],
   "source": [
    "tensor_sentences = tokenizer.texts_to_sequences(phrasesSpacy)\n",
    "print(type(tensor_sentences))\n",
    "print(phrasesSpacy[0],tensor_sentences[0])\n",
    "# enfin on padd le tout pour pouvoir l'utiliser dans un réseau de neurones\n",
    "tensor_sentences = tf.keras.preprocessing.sequence.pad_sequences(tensor_sentences,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 ----> comment\n",
      "5 ----> la\n",
      "38 ----> mobilité\n",
      "211 ----> est-elle\n",
      "1564 ----> vérifiée\n",
      "15 ----> pour\n",
      "4 ----> les\n",
      "97 ----> doubles\n",
      "85 ----> diplômes\n",
      "18 ----> en\n",
      "80 ----> france\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "# Fonction qui convertit un mot en son représentant entier\n",
    "def convert(tokenizer, tensor):\n",
    "    for t in tensor: # t est un entier élément du tenseur\n",
    "        if t != 0:\n",
    "            print (\"%d ----> %s\" % (t, tokenizer.index_word[t]))\n",
    "convert(tokenizer, tensor_sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define problem numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizer.index_word` est un dictionnaire dont les clés sont des entiers et les valeurs sont des struings (mots du vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:\n",
      "<class 'numpy.ndarray'>\n",
      "(2201, 347)\n",
      "tokenizer:\n",
      "<class 'keras_preprocessing.text.Tokenizer'>\n",
      "<class 'dict'>\n",
      "nombre de données: 2201\n",
      "longueur max phrases en mots: 347\n",
      "taille du vocabulaire: 2555\n",
      "dimension de l'embedding: 16\n"
     ]
    }
   ],
   "source": [
    "print('tensor:')\n",
    "print(type(tensor_sentences))\n",
    "print(np.shape(tensor_sentences))\n",
    "tensor_sentences[0]\n",
    "print(\"tokenizer:\")\n",
    "print(type(tokenizer))\n",
    "print(type(tokenizer.index_word))\n",
    "\n",
    "vocab_inp_size = len(tokenizer.word_index)\n",
    "n_data,max_length = tensor_sentences.shape\n",
    "embedding_dim = 16\n",
    "\n",
    "print(f\"nombre de données: {n_data}\\nlongueur max phrases en mots: {max_length}\\ntaille du vocabulaire: {vocab_inp_size}\\ndimension de l'embedding: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Split the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "1760 1760 441 441\n",
      "62 ----> dois\n",
      "23 ----> -je\n",
      "44 ----> faire\n",
      "8 ----> le\n",
      "216 ----> s8\n",
      "446 ----> central\n",
      "9 ----> à\n",
      "43 ----> lyon\n",
      "15 ----> pour\n",
      "44 ----> faire\n",
      "7 ----> un\n",
      "33 ----> double\n",
      "22 ----> diplôme\n",
      "9 ----> à\n",
      "3 ----> l'\n",
      "359 ----> ensae\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and validation sets using an 80/20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(tensor_sentences, tensor_sentences, test_size=0.2)\n",
    "\n",
    "print(type(input_tensor_train), type(target_tensor_train))\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "\n",
    "# on observe ce qu'il y a dans ces données: si on rééxécute ça change, c'est parce qu'il y a un shuffle aléatoire\n",
    "convert(tokenizer, input_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "# Step 5: create Encoder and Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "# Encoder class\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x)\n",
    "        return output, state\n",
    "        # hidden state shape == (batch_size, hidden size)\n",
    "        # output       shape == (batch_size, max_len, hidden size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder class\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, dec_units,max_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "        self.reshape = tf.keras.layers.Reshape([max_length])\n",
    "\n",
    "    def call(self, enc_output,enc_hidden):\n",
    "        attention_outputs, attention_scores = tf.keras.layers.Attention()([enc_output, enc_hidden], return_attention_scores=True)\n",
    "        context = attention_outputs * enc_output\n",
    "        final_output = self.dense(context)\n",
    "        final_output = self.reshape(final_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60gSVh05Jl6l"
   },
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, 128)\n",
    "decoder = Decoder(128,10)\n",
    "\n",
    "enc_in = tf.random.uniform(\n",
    "    (6,10),\n",
    "    minval=0,\n",
    "    maxval=60,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=\"dummy_input_encoder\"\n",
    ")\n",
    "\n",
    "\n",
    "print('Encoder Input        shape: (batch_size, timesteps)                {}'.format(enc_in.shape))\n",
    "enc_output, enc_hidden = encoder(enc_in)\n",
    "\n",
    "print('Encoder Output       shape: (batch_size, sequence_length, units)   {}'.format(enc_output.shape))\n",
    "print('Encoder Hidden_state shape: (batch_size, units)                    {}'.format(enc_hidden.shape))\n",
    "\n",
    "output = decoder(enc_output)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dec_out = decoder(enc_output)\n",
    "dec_out.shape\n",
    "#print('Attention output: (batch_size, sequence_length, units)', attention_outputs.shape)\n",
    "#print('Attention scores: (batch_size, sequence_length, units)', attention_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, vocab_inp_size, max_length, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = 128\n",
    "        self.encoder = Encoder(vocab_inp_size, embedding_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim,max_length)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc_output,enc_hidden = self.encoder(inputs)\n",
    "        out_dec = self.decoder(enc_output,enc_hidden)\n",
    "        return out_dec\n",
    "    \n",
    "    def vectoriser(self, phrases): # phrases doit être une liste de strings\n",
    "        l = tokenizer.texts_to_sequences(phrases)\n",
    "        for ll in l:\n",
    "            ll += (max_length-len(ll))*[0]\n",
    "            \n",
    "        return(self.encoder(np.asarray(l))[1])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "autoenc = Autoencoder(embedding_dim,vocab_inp_size,max_length,128)\n",
    "autoenc.compile(optimizer='Adam', loss=tf.losses.MeanSquaredError(), metrics = [\"accuracy\"]) # losses.MeanSquaredError() losses.CosineSimilarity()\n",
    "autoenc.build(input_shape=input_tensor_train.shape)\n",
    "\n",
    "\n",
    "# input_tensor_train.shape, autoenc(input_tensor_train).shape # ne pas décommenter si gros gros tenseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "55/55 [==============================] - 3s 26ms/step - loss: 11255.3975 - accuracy: 0.0335 - val_loss: 11224.2354 - val_accuracy: 0.1224\n",
      "Epoch 2/30\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 11126.0781 - accuracy: 0.1199 - val_loss: 11045.0010 - val_accuracy: 0.1746\n",
      "Epoch 3/30\n",
      "55/55 [==============================] - 1s 20ms/step - loss: 10983.4795 - accuracy: 0.0682 - val_loss: 10917.6475 - val_accuracy: 0.0272\n",
      "Epoch 4/30\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 10821.4521 - accuracy: 0.0420 - val_loss: 10759.8926 - val_accuracy: 0.0499\n",
      "Epoch 5/30\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 10668.9473 - accuracy: 0.0761 - val_loss: 10601.2373 - val_accuracy: 0.0884\n",
      "Epoch 6/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 10511.7490 - accuracy: 0.1040 - val_loss: 10440.2041 - val_accuracy: 0.0794\n",
      "Epoch 7/30\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 10352.2754 - accuracy: 0.1114 - val_loss: 10277.2930 - val_accuracy: 0.1451\n",
      "Epoch 8/30\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 10211.4180 - accuracy: 0.1739 - val_loss: 10141.0254 - val_accuracy: 0.1950\n",
      "Epoch 9/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 10059.2070 - accuracy: 0.1983 - val_loss: 9991.8955 - val_accuracy: 0.2177\n",
      "Epoch 10/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 9931.8066 - accuracy: 0.2756 - val_loss: 9866.4062 - val_accuracy: 0.2449\n",
      "Epoch 11/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 9807.5596 - accuracy: 0.3068 - val_loss: 9765.6270 - val_accuracy: 0.2857\n",
      "Epoch 12/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 9712.0918 - accuracy: 0.3239 - val_loss: 9681.4004 - val_accuracy: 0.2857\n",
      "Epoch 13/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 9604.0459 - accuracy: 0.3472 - val_loss: 9572.5859 - val_accuracy: 0.3175\n",
      "Epoch 14/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 9482.8320 - accuracy: 0.3551 - val_loss: 9451.2627 - val_accuracy: 0.3197\n",
      "Epoch 15/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 9344.0020 - accuracy: 0.3631 - val_loss: 9330.9971 - val_accuracy: 0.3447\n",
      "Epoch 16/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 9233.2148 - accuracy: 0.3744 - val_loss: 9212.6914 - val_accuracy: 0.3583\n",
      "Epoch 17/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 9110.1592 - accuracy: 0.3744 - val_loss: 9101.4854 - val_accuracy: 0.3197\n",
      "Epoch 18/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8990.1260 - accuracy: 0.3818 - val_loss: 8996.7383 - val_accuracy: 0.3424\n",
      "Epoch 19/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8878.9580 - accuracy: 0.3812 - val_loss: 8887.7383 - val_accuracy: 0.3537\n",
      "Epoch 20/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8776.2627 - accuracy: 0.3881 - val_loss: 8788.5938 - val_accuracy: 0.3605\n",
      "Epoch 21/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8662.4092 - accuracy: 0.3818 - val_loss: 8691.3232 - val_accuracy: 0.3651\n",
      "Epoch 22/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8576.6084 - accuracy: 0.3852 - val_loss: 8597.5254 - val_accuracy: 0.3673\n",
      "Epoch 23/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8462.7354 - accuracy: 0.4006 - val_loss: 8517.4092 - val_accuracy: 0.3673\n",
      "Epoch 24/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8373.0371 - accuracy: 0.3886 - val_loss: 8422.6289 - val_accuracy: 0.3696\n",
      "Epoch 25/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8272.3857 - accuracy: 0.4102 - val_loss: 8335.4004 - val_accuracy: 0.3741\n",
      "Epoch 26/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8181.0317 - accuracy: 0.4080 - val_loss: 8251.8154 - val_accuracy: 0.3764\n",
      "Epoch 27/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8099.7861 - accuracy: 0.4085 - val_loss: 8170.8687 - val_accuracy: 0.3810\n",
      "Epoch 28/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 8010.5239 - accuracy: 0.4080 - val_loss: 8089.7090 - val_accuracy: 0.3787\n",
      "Epoch 29/30\n",
      "55/55 [==============================] - 1s 18ms/step - loss: 7934.3745 - accuracy: 0.4119 - val_loss: 8006.9575 - val_accuracy: 0.3810\n",
      "Epoch 30/30\n",
      "55/55 [==============================] - 1s 19ms/step - loss: 7848.9526 - accuracy: 0.4148 - val_loss: 7931.9780 - val_accuracy: 0.3832\n"
     ]
    }
   ],
   "source": [
    "history = autoenc.fit(input_tensor_train,target_tensor_train,\n",
    "                epochs=30,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(input_tensor_val,target_tensor_val),\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\"Comment valider en A?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       "array([[-0.98171586,  0.97985595, -0.9999898 ,  0.9993942 ,  0.9998778 ,\n",
       "        -0.9656992 ,  0.99983764, -0.9998682 , -0.98909116, -0.9970181 ,\n",
       "         0.99841285,  0.99994606, -0.99698186, -0.97370654,  0.99970466,\n",
       "        -0.9999287 ,  0.9913932 , -0.99125266,  0.99941385, -0.9994484 ,\n",
       "        -0.9998305 ,  0.99965847,  0.9993604 , -0.9999437 , -0.9971719 ,\n",
       "         0.99582857, -0.999967  ,  0.9786366 ,  0.99961025,  0.9789447 ,\n",
       "         0.99991244,  0.99986875, -0.99973404,  0.9982236 ,  0.99997485,\n",
       "         0.9922872 , -0.99997354, -0.9999091 , -0.9996596 , -0.9996623 ,\n",
       "        -0.9809651 , -0.99983215, -0.99979395,  0.9841423 , -0.99987566,\n",
       "         0.9994867 , -0.9999078 ,  0.9991239 ,  0.9999648 ,  0.9994954 ,\n",
       "         0.99982506,  0.99925613,  0.9999089 , -0.9999526 ,  0.9961214 ,\n",
       "         0.9999591 , -0.98087054,  0.99753135,  0.99996156,  0.9945561 ,\n",
       "         0.9994759 , -0.9993938 , -0.9996772 ,  0.9976153 ,  0.99988604,\n",
       "         0.9996605 , -0.98577696,  0.9999346 ,  0.9998075 ,  0.9996744 ,\n",
       "         0.99985653, -0.99998766,  0.952806  ,  0.9998458 , -0.9914014 ,\n",
       "         0.99996495,  0.99092305, -0.9782235 , -0.9835945 , -0.9997839 ,\n",
       "         0.9999037 ,  0.97833115,  0.9982498 , -0.99993265, -0.99899065,\n",
       "         0.96337426, -0.99988407, -0.9995463 , -0.99979025, -0.98712593,\n",
       "        -0.99964124,  0.9998394 ,  0.99990875, -0.99993217,  0.9999113 ,\n",
       "        -0.99952424,  0.9998882 , -0.9997553 ,  0.95760393,  0.97232866,\n",
       "        -0.99994534,  0.999913  , -0.99996257,  0.99939233,  0.9846194 ,\n",
       "         0.9865833 ,  0.9997788 , -0.96885204, -0.99175066,  0.99985975,\n",
       "         0.997536  ,  0.99996495,  0.9984096 , -0.99170786, -0.9855801 ,\n",
       "         0.9998257 , -0.9998584 ,  0.99713546,  0.9994788 ,  0.9997017 ,\n",
       "         0.99380314, -0.9992938 ,  0.9998707 , -0.9840492 ,  0.99973834,\n",
       "        -0.9998863 ,  0.99991953,  0.99760085]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.vectoriser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "networks_seq2seq_nmt.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
