{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-8q8rRRWcp6"
   },
   "source": [
    "# TensorFlow Autoencodeur avec attention pour le PAr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpySVYWJhxaV"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Moi j'ai installé tf addons par `pip install tensorflow-addons==0.13.0` (ET NON PAS `conda install -c esri tensorflow-addons`). Voir les compatibilités [sur le github de tensorflow_addons](https://github.com/tensorflow/addons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kxfdP4hJUPB"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:36:06) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii_vg-XNXTil"
   },
   "source": [
    "# Step 1: Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PvRnGWnvXm6l"
   },
   "outputs": [],
   "source": [
    "path_reglement_scol  = './word2vec_docs_scol_traités/corpus.txt'\n",
    "path_questions_scol  = './word2vec_docs_scol_traités/toutes-les-questions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFKB2c_tX4wU"
   },
   "source": [
    "# Step 2: Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as regex\n",
    "# acquisition du texte\n",
    "reglement_scol = io.open(path_reglement_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "questions_scol = io.open(path_questions_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "texte = reglement_scol + ' ' + questions_scol\n",
    "texte = regex.sub(\"\\n\", \" \", texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée d'abord une liste de phrases dont chaque mot est séparé par un espace. On a besoin de `spacy` pour découper correctement les mots en français d'abord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases parsées par NLTK\n",
      "phrases tokénisées par spacy\n",
      "phrases découpées en tokens puis refusionnées\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "phrases = nltk.tokenize.sent_tokenize(texte, language='french')\n",
    "print('phrases parsées par NLTK')\n",
    "phrasesTokeniseesSpacy = [nlp(s) for s in phrases]\n",
    "print('phrases tokénisées par spacy')\n",
    "phrasesSpacy = [' '.join([token.text.lower() for token in doc]) for doc in phrasesTokeniseesSpacy]\n",
    "print('phrases découpées en tokens puis refusionnées')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les listes inutiles désormais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del phrasesTokeniseesSpacy\n",
    "del phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un tokéniseur adapté à notre vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters='')\n",
    "# créer un tokenizer adapté à tout le vocabulaire des phrases\n",
    "tokenizer.fit_on_texts(phrasesSpacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer les tenseurs pour toutes les phrases et padder le tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "le règlement de scolarité présente les modalités d' admission à l' école centrale de lyon , les objectifs et les modalités de l' évaluation des connaissances et des compétences de la formation ingénieur , les modalités de diversification de cette formation et les conditions d' obtention des diplômes de l' école centrale de lyon , hors diplômes de master co-accrédités et diplôme d' ingénieur energie en alternance . [8, 131, 1, 59, 860, 4, 102, 6, 175, 9, 3, 25, 46, 1, 43, 10, 4, 861, 16, 4, 102, 1, 3, 77, 12, 90, 16, 12, 104, 1, 5, 42, 88, 10, 4, 102, 1, 1565, 1, 166, 42, 16, 4, 285, 6, 214, 12, 85, 1, 3, 25, 46, 1, 43, 10, 390, 85, 1, 247, 1189, 16, 22, 6, 88, 1190, 18, 615, 13]\n"
     ]
    }
   ],
   "source": [
    "tensor_sentences = tokenizer.texts_to_sequences(phrasesSpacy)\n",
    "print(type(tensor_sentences))\n",
    "print(phrasesSpacy[0],tensor_sentences[0])\n",
    "# enfin on padd le tout pour pouvoir l'utiliser dans un réseau de neurones\n",
    "tensor_sentences = tf.keras.preprocessing.sequence.pad_sequences(tensor_sentences,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 ----> comment\n",
      "5 ----> la\n",
      "38 ----> mobilité\n",
      "211 ----> est-elle\n",
      "1564 ----> vérifiée\n",
      "15 ----> pour\n",
      "4 ----> les\n",
      "97 ----> doubles\n",
      "85 ----> diplômes\n",
      "18 ----> en\n",
      "80 ----> france\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "# Fonction qui convertit un mot en son représentant entier\n",
    "def convert(tokenizer, tensor):\n",
    "    for t in tensor: # t est un entier élément du tenseur\n",
    "        if t != 0:\n",
    "            print (\"%d ----> %s\" % (t, tokenizer.index_word[t]))\n",
    "convert(tokenizer, tensor_sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define problem numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizer.index_word` est un dictionnaire dont les clés sont des entiers et les valeurs sont des struings (mots du vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:\n",
      "<class 'numpy.ndarray'>\n",
      "(2201, 347)\n",
      "tokenizer:\n",
      "<class 'keras_preprocessing.text.Tokenizer'>\n",
      "<class 'dict'>\n",
      "nombre de données: 2201\n",
      "longueur max phrases en mots: 347\n",
      "taille du vocabulaire: 2555\n",
      "dimension de l'embedding: 16\n"
     ]
    }
   ],
   "source": [
    "print('tensor:')\n",
    "print(type(tensor_sentences))\n",
    "print(np.shape(tensor_sentences))\n",
    "tensor_sentences[0]\n",
    "print(\"tokenizer:\")\n",
    "print(type(tokenizer))\n",
    "print(type(tokenizer.index_word))\n",
    "\n",
    "vocab_inp_size = len(tokenizer.word_index)\n",
    "n_data,max_length = tensor_sentences.shape\n",
    "embedding_dim = 16\n",
    "\n",
    "print(f\"nombre de données: {n_data}\\nlongueur max phrases en mots: {max_length}\\ntaille du vocabulaire: {vocab_inp_size}\\ndimension de l'embedding: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Split the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "1760 1760 441 441\n",
      "24 ----> qui\n",
      "62 ----> dois\n",
      "23 ----> -je\n",
      "387 ----> contacter\n",
      "9 ----> à\n",
      "3 ----> l'\n",
      "248 ----> administration\n",
      "15 ----> pour\n",
      "61 ----> valider\n",
      "82 ----> mon\n",
      "53 ----> stage\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and validation sets using an 80/20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(tensor_sentences, tensor_sentences, test_size=0.2)\n",
    "\n",
    "print(type(input_tensor_train), type(target_tensor_train))\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "\n",
    "# on observe ce qu'il y a dans ces données: si on rééxécute ça change, c'est parce qu'il y a un shuffle aléatoire\n",
    "convert(tokenizer, input_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "# Step 5: create Encoder and Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "# Encoder class\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x)\n",
    "        return output, state\n",
    "        # hidden state shape == (batch_size, hidden size)\n",
    "        # output       shape == (batch_size, max_len, hidden size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder class\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, dec_units,max_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "        self.reshape = tf.keras.layers.Reshape([max_length])\n",
    "\n",
    "    def call(self, enc_output,enc_hidden):\n",
    "        attention_outputs, attention_scores = tf.keras.layers.Attention()([enc_output, enc_hidden], return_attention_scores=True)\n",
    "        context = attention_outputs * enc_output\n",
    "        final_output = self.dense(context)\n",
    "        final_output = self.reshape(final_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60gSVh05Jl6l"
   },
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, 128)\n",
    "decoder = Decoder(128,10)\n",
    "\n",
    "enc_in = tf.random.uniform(\n",
    "    (6,10),\n",
    "    minval=0,\n",
    "    maxval=60,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=\"dummy_input_encoder\"\n",
    ")\n",
    "\n",
    "\n",
    "print('Encoder Input        shape: (batch_size, timesteps)                {}'.format(enc_in.shape))\n",
    "enc_output, enc_hidden = encoder(enc_in)\n",
    "\n",
    "print('Encoder Output       shape: (batch_size, sequence_length, units)   {}'.format(enc_output.shape))\n",
    "print('Encoder Hidden_state shape: (batch_size, units)                    {}'.format(enc_hidden.shape))\n",
    "\n",
    "output = decoder(enc_output)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dec_out = decoder(enc_output)\n",
    "dec_out.shape\n",
    "#print('Attention output: (batch_size, sequence_length, units)', attention_outputs.shape)\n",
    "#print('Attention scores: (batch_size, sequence_length, units)', attention_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, vocab_inp_size, max_length, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = 128\n",
    "        self.encoder = Encoder(vocab_inp_size, embedding_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim,max_length)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc_output,enc_hidden = self.encoder(inputs)\n",
    "        out_dec = self.decoder(enc_output,enc_hidden)\n",
    "        return out_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "autoenc = Autoencoder(embedding_dim,vocab_inp_size,max_length,128)\n",
    "autoenc.compile(optimizer='Adam', loss=tf.losses.MeanSquaredError(), metrics = [\"accuracy\"]) # losses.MeanSquaredError() losses.CosineSimilarity()\n",
    "autoenc.build(input_shape=input_tensor_train.shape)\n",
    "\n",
    "\n",
    "# input_tensor_train.shape, autoenc(input_tensor_train).shape # ne pas décommenter si gros gros tenseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "28/28 [==============================] - 3s 42ms/step - loss: 11224.7773 - accuracy: 0.0068 - val_loss: 11567.1611 - val_accuracy: 0.0454\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 11135.5332 - accuracy: 0.0642 - val_loss: 11470.2002 - val_accuracy: 0.0862\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 11018.1689 - accuracy: 0.0795 - val_loss: 11338.7100 - val_accuracy: 0.0862\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10910.5508 - accuracy: 0.0733 - val_loss: 11229.9717 - val_accuracy: 0.0590\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 10812.9434 - accuracy: 0.0710 - val_loss: 11118.0371 - val_accuracy: 0.0590\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10713.2861 - accuracy: 0.0648 - val_loss: 11009.6240 - val_accuracy: 0.0385\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10621.5234 - accuracy: 0.0301 - val_loss: 10910.8818 - val_accuracy: 0.0227\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10520.6895 - accuracy: 0.0250 - val_loss: 10810.8438 - val_accuracy: 0.0249\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10445.7910 - accuracy: 0.0222 - val_loss: 10725.7275 - val_accuracy: 0.0249\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 10364.9971 - accuracy: 0.0199 - val_loss: 10649.9551 - val_accuracy: 0.0227\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10291.5293 - accuracy: 0.0267 - val_loss: 10576.5293 - val_accuracy: 0.0272\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10234.7100 - accuracy: 0.0250 - val_loss: 10514.7666 - val_accuracy: 0.0317\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10411.6270 - accuracy: 0.0403 - val_loss: 11319.5068 - val_accuracy: 0.0295\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10732.3613 - accuracy: 0.0477 - val_loss: 10910.4082 - val_accuracy: 0.0363\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10453.8135 - accuracy: 0.0648 - val_loss: 10672.9658 - val_accuracy: 0.0431\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10240.1045 - accuracy: 0.1386 - val_loss: 10493.9941 - val_accuracy: 0.1270\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10135.5547 - accuracy: 0.0881 - val_loss: 10401.7344 - val_accuracy: 0.0363\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10034.0654 - accuracy: 0.0716 - val_loss: 10297.9219 - val_accuracy: 0.0454\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9943.8398 - accuracy: 0.0886 - val_loss: 10231.8359 - val_accuracy: 0.0567\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9877.5781 - accuracy: 0.1273 - val_loss: 10231.4629 - val_accuracy: 0.0952\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9828.1904 - accuracy: 0.1943 - val_loss: 10144.2734 - val_accuracy: 0.1497\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9767.3623 - accuracy: 0.2136 - val_loss: 10223.3447 - val_accuracy: 0.1587\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9804.9844 - accuracy: 0.2631 - val_loss: 10063.5361 - val_accuracy: 0.2041\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 9679.5205 - accuracy: 0.2670 - val_loss: 10020.7168 - val_accuracy: 0.2041\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9635.0596 - accuracy: 0.2733 - val_loss: 9985.5098 - val_accuracy: 0.2109\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9593.0566 - accuracy: 0.2858 - val_loss: 9948.7656 - val_accuracy: 0.2200\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9547.2842 - accuracy: 0.2881 - val_loss: 9935.1182 - val_accuracy: 0.2517\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9498.3633 - accuracy: 0.3182 - val_loss: 9901.0068 - val_accuracy: 0.2653\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9450.1338 - accuracy: 0.3409 - val_loss: 9829.2490 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9387.9053 - accuracy: 0.3392 - val_loss: 9784.2930 - val_accuracy: 0.2812\n"
     ]
    }
   ],
   "source": [
    "history = autoenc.fit(input_tensor_train,target_tensor_train,\n",
    "                epochs=30,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(input_tensor_val,target_tensor_val),\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "networks_seq2seq_nmt.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
