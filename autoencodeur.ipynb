{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-8q8rRRWcp6"
   },
   "source": [
    "# TensorFlow Autoencodeur avec attention pour le PAr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpySVYWJhxaV"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Moi j'ai installé tf addons par `pip install tensorflow-addons==0.13.0` (ET NON PAS `conda install -c esri tensorflow-addons`). Voir les compatibilités [sur le github de tensorflow_addons](https://github.com/tensorflow/addons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kxfdP4hJUPB"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:36:06) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii_vg-XNXTil"
   },
   "source": [
    "# Step 1: Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PvRnGWnvXm6l"
   },
   "outputs": [],
   "source": [
    "path_reglement_scol  = './word2vec_docs_scol_traités/corpus.txt'\n",
    "path_questions_scol  = './word2vec_docs_scol_traités/toutes-les-questions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFKB2c_tX4wU"
   },
   "source": [
    "# Step 2: Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as regex\n",
    "# acquisition du texte\n",
    "reglement_scol = io.open(path_reglement_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "questions_scol = io.open(path_questions_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "texte = reglement_scol + ' ' + questions_scol\n",
    "texte = regex.sub(\"\\n\", \" \", texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée d'abord une liste de phrases dont chaque mot est séparé par un espace. On a besoin de `spacy` pour découper correctement les mots en français d'abord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases parsées par NLTK\n",
      "phrases tokénisées par spacy\n",
      "phrases découpées en tokens puis refusionnées\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "phrases = nltk.tokenize.sent_tokenize(texte, language='french')\n",
    "print('phrases parsées par NLTK')\n",
    "phrasesTokeniseesSpacy = [nlp(s) for s in phrases]\n",
    "print('phrases tokénisées par spacy')\n",
    "phrasesSpacy = [' '.join([token.text.lower() for token in doc]) for doc in phrasesTokeniseesSpacy]\n",
    "print('phrases découpées en tokens puis refusionnées')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les listes inutiles désormais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del phrasesTokeniseesSpacy\n",
    "del phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un tokéniseur adapté à notre vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters='')\n",
    "# créer un tokenizer adapté à tout le vocabulaire des phrases\n",
    "tokenizer.fit_on_texts(phrasesSpacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer les tenseurs pour toutes les phrases et padder le tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "le règlement de scolarité présente les modalités d' admission à l' école centrale de lyon , les objectifs et les modalités de l' évaluation des connaissances et des compétences de la formation ingénieur , les modalités de diversification de cette formation et les conditions d' obtention des diplômes de l' école centrale de lyon , hors diplômes de master co-accrédités et diplôme d' ingénieur energie en alternance . [8, 131, 1, 59, 860, 4, 102, 6, 175, 9, 3, 25, 46, 1, 43, 10, 4, 861, 16, 4, 102, 1, 3, 77, 12, 90, 16, 12, 104, 1, 5, 42, 88, 10, 4, 102, 1, 1565, 1, 166, 42, 16, 4, 285, 6, 214, 12, 85, 1, 3, 25, 46, 1, 43, 10, 390, 85, 1, 247, 1189, 16, 22, 6, 88, 1190, 18, 615, 13]\n"
     ]
    }
   ],
   "source": [
    "tensor_sentences = tokenizer.texts_to_sequences(phrasesSpacy)\n",
    "print(type(tensor_sentences))\n",
    "print(phrasesSpacy[0],tensor_sentences[0])\n",
    "# enfin on padd le tout pour pouvoir l'utiliser dans un réseau de neurones\n",
    "tensor_sentences = tf.keras.preprocessing.sequence.pad_sequences(tensor_sentences,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 ----> comment\n",
      "5 ----> la\n",
      "38 ----> mobilité\n",
      "211 ----> est-elle\n",
      "1564 ----> vérifiée\n",
      "15 ----> pour\n",
      "4 ----> les\n",
      "97 ----> doubles\n",
      "85 ----> diplômes\n",
      "18 ----> en\n",
      "80 ----> france\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "# Fonction qui convertit un mot en son représentant entier\n",
    "def convert(tokenizer, tensor):\n",
    "    for t in tensor: # t est un entier élément du tenseur\n",
    "        if t != 0:\n",
    "            print (\"%d ----> %s\" % (t, tokenizer.index_word[t]))\n",
    "convert(tokenizer, tensor_sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define problem numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizer.index_word` est un dictionnaire dont les clés sont des entiers et les valeurs sont des struings (mots du vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:\n",
      "<class 'numpy.ndarray'>\n",
      "(2201, 347)\n",
      "tokenizer:\n",
      "<class 'keras_preprocessing.text.Tokenizer'>\n",
      "<class 'dict'>\n",
      "nombre de données: 2201\n",
      "longueur max phrases en mots: 347\n",
      "taille du vocabulaire: 2555\n",
      "dimension de l'embedding: 16\n"
     ]
    }
   ],
   "source": [
    "print('tensor:')\n",
    "print(type(tensor_sentences))\n",
    "print(np.shape(tensor_sentences))\n",
    "tensor_sentences[0]\n",
    "print(\"tokenizer:\")\n",
    "print(type(tokenizer))\n",
    "print(type(tokenizer.index_word))\n",
    "\n",
    "vocab_inp_size = len(tokenizer.word_index)\n",
    "n_data,max_length = tensor_sentences.shape\n",
    "embedding_dim = 16\n",
    "\n",
    "print(f\"nombre de données: {n_data}\\nlongueur max phrases en mots: {max_length}\\ntaille du vocabulaire: {vocab_inp_size}\\ndimension de l'embedding: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Split the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "1760 1760 441 441\n",
      "24 ----> qui\n",
      "409 ----> évalue\n",
      "8 ----> le\n",
      "287 ----> statut\n",
      "1 ----> de\n",
      "184 ----> handicap\n",
      "1 ----> de\n",
      "3 ----> l'\n",
      "108 ----> étudiant\n",
      "591 ----> afin\n",
      "6 ----> d'\n",
      "65 ----> obtenir\n",
      "12 ----> des\n",
      "1555 ----> adaptations\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and validation sets using an 80/20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(tensor_sentences, tensor_sentences, test_size=0.2)\n",
    "\n",
    "print(type(input_tensor_train), type(target_tensor_train))\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "\n",
    "# on observe ce qu'il y a dans ces données: si on rééxécute ça change, c'est parce qu'il y a un shuffle aléatoire\n",
    "convert(tokenizer, input_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "# Step 5: create Encoder and Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "# Encoder class\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x)\n",
    "        return output, state\n",
    "        # hidden state shape == (batch_size, hidden size)\n",
    "        # output       shape == (batch_size, max_len, hidden size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder class\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, dec_units,max_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "        self.reshape = tf.keras.layers.Reshape([max_length])\n",
    "\n",
    "    def call(self, enc_output,enc_hidden):\n",
    "        attention_outputs, attention_scores = tf.keras.layers.Attention()([enc_output, enc_hidden], return_attention_scores=True)\n",
    "        context = attention_outputs * enc_output\n",
    "        final_output = self.dense(context)\n",
    "        final_output = self.reshape(final_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60gSVh05Jl6l"
   },
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, 128)\n",
    "decoder = Decoder(128,10)\n",
    "\n",
    "enc_in = tf.random.uniform(\n",
    "    (6,10),\n",
    "    minval=0,\n",
    "    maxval=60,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=\"dummy_input_encoder\"\n",
    ")\n",
    "\n",
    "\n",
    "print('Encoder Input        shape: (batch_size, timesteps)                {}'.format(enc_in.shape))\n",
    "enc_output, enc_hidden = encoder(enc_in)\n",
    "\n",
    "print('Encoder Output       shape: (batch_size, sequence_length, units)   {}'.format(enc_output.shape))\n",
    "print('Encoder Hidden_state shape: (batch_size, units)                    {}'.format(enc_hidden.shape))\n",
    "\n",
    "output = decoder(enc_output)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dec_out = decoder(enc_output)\n",
    "dec_out.shape\n",
    "#print('Attention output: (batch_size, sequence_length, units)', attention_outputs.shape)\n",
    "#print('Attention scores: (batch_size, sequence_length, units)', attention_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, vocab_inp_size, max_length, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = 128\n",
    "        self.encoder = Encoder(vocab_inp_size, embedding_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim,max_length)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc_output,enc_hidden = self.encoder(inputs)\n",
    "        out_dec = self.decoder(enc_output,enc_hidden)\n",
    "        return out_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "autoenc = Autoencoder(embedding_dim,vocab_inp_size,max_length,128)\n",
    "autoenc.compile(optimizer='Adam', loss=tf.losses.MeanSquaredError(), metrics = [\"accuracy\"]) # losses.MeanSquaredError() losses.CosineSimilarity()\n",
    "autoenc.build(input_shape=input_tensor_train.shape)\n",
    "\n",
    "\n",
    "# input_tensor_train.shape, autoenc(input_tensor_train).shape # ne pas décommenter si gros gros tenseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "28/28 [==============================] - 4s 44ms/step - loss: 11302.7129 - accuracy: 0.0119 - val_loss: 11275.9990 - val_accuracy: 0.0249\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 11208.1621 - accuracy: 0.0602 - val_loss: 11180.9004 - val_accuracy: 0.0952\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 11113.8633 - accuracy: 0.0795 - val_loss: 11069.5586 - val_accuracy: 0.1088\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 11000.5713 - accuracy: 0.1091 - val_loss: 10941.8301 - val_accuracy: 0.1247\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 10886.8535 - accuracy: 0.0972 - val_loss: 10813.7324 - val_accuracy: 0.0930\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 10766.7266 - accuracy: 0.0733 - val_loss: 10693.4033 - val_accuracy: 0.0794\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 10653.8271 - accuracy: 0.0523 - val_loss: 10578.5098 - val_accuracy: 0.0431\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10554.2148 - accuracy: 0.0301 - val_loss: 10483.3750 - val_accuracy: 0.0363\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 10465.8320 - accuracy: 0.0335 - val_loss: 10393.4580 - val_accuracy: 0.0454\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 10388.3672 - accuracy: 0.0437 - val_loss: 10313.8223 - val_accuracy: 0.0499\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 10301.2275 - accuracy: 0.0574 - val_loss: 10237.6289 - val_accuracy: 0.0544\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 10248.8193 - accuracy: 0.0722 - val_loss: 10184.9922 - val_accuracy: 0.0680\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 10191.0547 - accuracy: 0.1114 - val_loss: 10116.3828 - val_accuracy: 0.0930\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 10120.3945 - accuracy: 0.1244 - val_loss: 10117.9883 - val_accuracy: 0.1134\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10050.0977 - accuracy: 0.1585 - val_loss: 10054.4043 - val_accuracy: 0.1474\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 10013.8096 - accuracy: 0.2051 - val_loss: 10175.4678 - val_accuracy: 0.1746\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9926.3740 - accuracy: 0.2199 - val_loss: 9899.5830 - val_accuracy: 0.1927\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9876.0322 - accuracy: 0.2540 - val_loss: 9881.1104 - val_accuracy: 0.2290\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9824.0898 - accuracy: 0.2795 - val_loss: 9792.6006 - val_accuracy: 0.2358\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9763.1826 - accuracy: 0.2875 - val_loss: 9742.5352 - val_accuracy: 0.2358\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9716.0947 - accuracy: 0.2949 - val_loss: 9698.3652 - val_accuracy: 0.2562\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9670.8037 - accuracy: 0.3051 - val_loss: 9680.3262 - val_accuracy: 0.2653\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9626.6670 - accuracy: 0.3193 - val_loss: 9611.1670 - val_accuracy: 0.2766\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9649.3027 - accuracy: 0.3227 - val_loss: 9632.8008 - val_accuracy: 0.2789\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9538.6934 - accuracy: 0.3506 - val_loss: 9550.0918 - val_accuracy: 0.2880\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9489.1289 - accuracy: 0.3449 - val_loss: 9526.7246 - val_accuracy: 0.2948\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9443.2578 - accuracy: 0.3403 - val_loss: 9470.4990 - val_accuracy: 0.3016\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9398.0518 - accuracy: 0.3381 - val_loss: 9435.5322 - val_accuracy: 0.3039\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 9314.5234 - accuracy: 0.3460 - val_loss: 9387.3311 - val_accuracy: 0.3061\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 9234.4580 - accuracy: 0.3631 - val_loss: 9335.9102 - val_accuracy: 0.3175\n"
     ]
    }
   ],
   "source": [
    "history = autoenc.fit(input_tensor_train,target_tensor_train,\n",
    "                epochs=30,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(input_tensor_val,target_tensor_val),\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "networks_seq2seq_nmt.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
