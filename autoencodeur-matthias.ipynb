{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-8q8rRRWcp6"
   },
   "source": [
    "# TensorFlow Autoencodeur avec attention pour le PAr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpySVYWJhxaV"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Moi j'ai installé tf addons par `pip install tensorflow-addons==0.13.0` (ET NON PAS `conda install -c esri tensorflow-addons`). Voir les compatibilités [sur le github de tensorflow_addons](https://github.com/tensorflow/addons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_kxfdP4hJUPB"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-addons==0.11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:36:06) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ii_vg-XNXTil"
   },
   "source": [
    "# Step 1: Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PvRnGWnvXm6l"
   },
   "outputs": [],
   "source": [
    "path_reglement_scol  = './word2vec_docs_scol_traités/corpus.txt'\n",
    "path_questions_scol  = './word2vec_docs_scol_traités/toutes-les-questions.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFKB2c_tX4wU"
   },
   "source": [
    "# Step 2: Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as regex\n",
    "# acquisition du texte\n",
    "reglement_scol = io.open(path_reglement_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "questions_scol = io.open(path_questions_scol, encoding='UTF-8').read()#.strip().split('\\n')\n",
    "texte = reglement_scol + ' ' + questions_scol\n",
    "texte = regex.sub(\"\\n\", \" \", texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée d'abord une liste de phrases dont chaque mot est séparé par un espace. On a besoin de `spacy` pour découper correctement les mots en français d'abord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases parsées par NLTK\n",
      "phrases tokénisées par spacy\n",
      "phrases découpées en tokens puis refusionnées\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "phrases = nltk.tokenize.sent_tokenize(texte, language='french')\n",
    "print('phrases parsées par NLTK')\n",
    "phrasesTokeniseesSpacy = [nlp(s) for s in phrases]\n",
    "print('phrases tokénisées par spacy')\n",
    "phrasesSpacy = [' '.join([token.text.lower() for token in doc]) for doc in phrasesTokeniseesSpacy]\n",
    "print('phrases découpées en tokens puis refusionnées')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les listes inutiles désormais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del phrasesTokeniseesSpacy\n",
    "del phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un tokéniseur adapté à notre vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters='')\n",
    "# créer un tokenizer adapté à tout le vocabulaire des phrases\n",
    "tokenizer.fit_on_texts(phrasesSpacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer les tenseurs pour toutes les phrases et padder le tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "le règlement de scolarité présente les modalités d' admission à l' école centrale de lyon , les objectifs et les modalités de l' évaluation des connaissances et des compétences de la formation ingénieur , les modalités de diversification de cette formation et les conditions d' obtention des diplômes de l' école centrale de lyon , hors diplômes de master co-accrédités et diplôme d' ingénieur energie en alternance . [8, 131, 1, 59, 860, 4, 102, 6, 175, 9, 3, 25, 46, 1, 43, 10, 4, 861, 16, 4, 102, 1, 3, 77, 12, 90, 16, 12, 104, 1, 5, 42, 88, 10, 4, 102, 1, 1565, 1, 166, 42, 16, 4, 285, 6, 214, 12, 85, 1, 3, 25, 46, 1, 43, 10, 390, 85, 1, 247, 1189, 16, 22, 6, 88, 1190, 18, 615, 13]\n"
     ]
    }
   ],
   "source": [
    "tensor_sentences = tokenizer.texts_to_sequences(phrasesSpacy)\n",
    "print(type(tensor_sentences))\n",
    "print(phrasesSpacy[0],tensor_sentences[0])\n",
    "# enfin on padd le tout pour pouvoir l'utiliser dans un réseau de neurones\n",
    "tensor_sentences = tf.keras.preprocessing.sequence.pad_sequences(tensor_sentences,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 ----> comment\n",
      "5 ----> la\n",
      "38 ----> mobilité\n",
      "211 ----> est-elle\n",
      "1564 ----> vérifiée\n",
      "15 ----> pour\n",
      "4 ----> les\n",
      "97 ----> doubles\n",
      "85 ----> diplômes\n",
      "18 ----> en\n",
      "80 ----> france\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "# Fonction qui convertit un mot en son représentant entier\n",
    "def convert(tokenizer, tensor):\n",
    "    for t in tensor: # t est un entier élément du tenseur\n",
    "        if t != 0:\n",
    "            print (\"%d ----> %s\" % (t, tokenizer.index_word[t]))\n",
    "convert(tokenizer, tensor_sentences[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define problem numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokenizer.index_word` est un dictionnaire dont les clés sont des entiers et les valeurs sont des struings (mots du vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:\n",
      "<class 'numpy.ndarray'>\n",
      "(2201, 347)\n",
      "tokenizer:\n",
      "<class 'keras_preprocessing.text.Tokenizer'>\n",
      "<class 'dict'>\n",
      "nombre de données: 2201\n",
      "longueur max phrases en mots: 347\n",
      "taille du vocabulaire: 2555\n",
      "dimension de l'embedding: 16\n"
     ]
    }
   ],
   "source": [
    "print('tensor:')\n",
    "print(type(tensor_sentences))\n",
    "print(np.shape(tensor_sentences))\n",
    "tensor_sentences[0]\n",
    "print(\"tokenizer:\")\n",
    "print(type(tokenizer))\n",
    "print(type(tokenizer.index_word))\n",
    "\n",
    "vocab_inp_size = len(tokenizer.word_index)\n",
    "n_data,max_length = tensor_sentences.shape\n",
    "embedding_dim = 16\n",
    "\n",
    "print(f\"nombre de données: {n_data}\\nlongueur max phrases en mots: {max_length}\\ntaille du vocabulaire: {vocab_inp_size}\\ndimension de l'embedding: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Split the train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "1760 1760 441 441\n",
      "37 ----> comment\n",
      "41 ----> puis\n",
      "23 ----> -je\n",
      "231 ----> trouver\n",
      "7 ----> un\n",
      "348 ----> référent\n",
      "191 ----> linguistique\n",
      "27 ----> si\n",
      "89 ----> je\n",
      "223 ----> suis\n",
      "500 ----> exempté\n",
      "17 ----> du\n",
      "47 ----> cours\n",
      "1 ----> de\n",
      "99 ----> langue\n",
      "2 ----> ?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create training and validation sets using an 80/20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(tensor_sentences, tensor_sentences, test_size=0.2)\n",
    "\n",
    "print(type(input_tensor_train), type(target_tensor_train))\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "\n",
    "# on observe ce qu'il y a dans ces données: si on rééxécute ça change, c'est parce qu'il y a un shuffle aléatoire\n",
    "convert(tokenizer, input_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "# Step 5: create Encoder and Decoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "# Encoder class\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, max_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        self.mask = tf.keras.layers.Masking(mask_value=0, input_shape=(None,max_length, embedding_dim))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.mask(x)\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x)\n",
    "        return output, state\n",
    "        # output       shape == (batch_size, max_len, encoding_units)\n",
    "        # output state shape == (batch_size, encoding_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_in (1, 10)\n",
      "out_enc (1, 10, 6) (1, 6)\n",
      "out_dec (1, 10)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size=60, embedding_dim=4, enc_units=6, max_length=10)\n",
    "enc_in = tf.random.uniform(\n",
    "    (1,10),\n",
    "    minval=0,\n",
    "    maxval=60,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=\"dummy_input_encoder\"\n",
    ")\n",
    "\n",
    "print(\"enc_in\",enc_in.shape)\n",
    "out_enc = encoder(enc_in)\n",
    "print(\"out_enc\", out_enc[0].shape,out_enc[1].shape)\n",
    "\n",
    "decoder = Decoder(max_length=10)\n",
    "out_dec = decoder(out_enc[0],out_enc[1])\n",
    "print(\"out_dec\",out_dec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder class\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, max_length):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.attention = tf.keras.layers.Attention()\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "        self.reshape = tf.keras.layers.Reshape([max_length])\n",
    "\n",
    "    def call(self, enc_output,enc_hidden):\n",
    "        attention_outputs, attention_scores = tf.keras.layers.Attention()([enc_output, enc_hidden], return_attention_scores=True)\n",
    "        #context = attention_outputs * enc_output\n",
    "        #final_output = self.dense(context)\n",
    "        final_output = self.reshape(attention_scores)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60gSVh05Jl6l"
   },
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, 128)\n",
    "decoder = Decoder(128,10)\n",
    "\n",
    "enc_in = tf.random.uniform(\n",
    "    (6,10),\n",
    "    minval=0,\n",
    "    maxval=60,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=\"dummy_input_encoder\"\n",
    ")\n",
    "\n",
    "\n",
    "print('Encoder Input        shape: (batch_size, timesteps)                {}'.format(enc_in.shape))\n",
    "enc_output, enc_hidden = encoder(enc_in)\n",
    "\n",
    "print('Encoder Output       shape: (batch_size, sequence_length, units)   {}'.format(enc_output.shape))\n",
    "print('Encoder Hidden_state shape: (batch_size, units)                    {}'.format(enc_hidden.shape))\n",
    "\n",
    "output = decoder(enc_output)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dec_out = decoder(enc_output)\n",
    "dec_out.shape\n",
    "#print('Attention output: (batch_size, sequence_length, units)', attention_outputs.shape)\n",
    "#print('Attention scores: (batch_size, sequence_length, units)', attention_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, vocab_inp_size, max_length, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = 128\n",
    "        self.encoder = Encoder(vocab_size=vocab_inp_size, embedding_dim=embedding_dim, enc_units=latent_dim, max_length=max_length)\n",
    "        self.decoder = Decoder(max_length=max_length)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc_output,enc_hidden = self.encoder(inputs)\n",
    "        out_dec = self.decoder(enc_output,enc_hidden)\n",
    "        return out_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"decoder_5\" (type Decoder).\n\nin user code:\n\n    File \"C:\\Users\\matth\\AppData\\Local\\Temp/ipykernel_9640/2569714999.py\", line 13, in call  *\n        final_output = self.reshape(attention_scores)\n    File \"C:\\Users\\matth\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"reshape_5\" (type Reshape).\n    \n    Cannot reshape a tensor with 1074867200 elements to shape [1760,347] (610720 elements) for '{{node decoder_5/reshape_5/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](decoder_5/attention/Identity, decoder_5/reshape_5/Reshape/shape)' with input shapes: [1760,347,1760], [2] and with input tensors computed as partial shapes: input[1] = [1760,347].\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(1760, 347, 1760), dtype=float32)\n\n\nCall arguments received:\n  • enc_output=tf.Tensor(shape=(1760, 347, 128), dtype=float32)\n  • enc_hidden=tf.Tensor(shape=(1760, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9640/3470349997.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     amsgrad=False)\n\u001b[0;32m      8\u001b[0m \u001b[0mautoenc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# losses.MeanSquaredError() losses.CosineSimilarity() tf.keras.losses.CategoricalCrossentropy()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mautoenc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensor_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    438\u001b[0m               'method accepts an `inputs` argument.')\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m           raise ValueError('You cannot build your model by calling `build` '\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9640/3252442784.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menc_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mout_dec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menc_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout_dec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    697\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"decoder_5\" (type Decoder).\n\nin user code:\n\n    File \"C:\\Users\\matth\\AppData\\Local\\Temp/ipykernel_9640/2569714999.py\", line 13, in call  *\n        final_output = self.reshape(attention_scores)\n    File \"C:\\Users\\matth\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"reshape_5\" (type Reshape).\n    \n    Cannot reshape a tensor with 1074867200 elements to shape [1760,347] (610720 elements) for '{{node decoder_5/reshape_5/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](decoder_5/attention/Identity, decoder_5/reshape_5/Reshape/shape)' with input shapes: [1760,347,1760], [2] and with input tensors computed as partial shapes: input[1] = [1760,347].\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(1760, 347, 1760), dtype=float32)\n\n\nCall arguments received:\n  • enc_output=tf.Tensor(shape=(1760, 347, 128), dtype=float32)\n  • enc_hidden=tf.Tensor(shape=(1760, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "autoenc = Autoencoder(embedding_dim,vocab_inp_size,max_length,latent_dim)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False)\n",
    "autoenc.compile(optimizer=adam, loss=tf.keras.losses.MeanSquaredError(), metrics = [\"accuracy\"]) # losses.MeanSquaredError() losses.CosineSimilarity() tf.keras.losses.CategoricalCrossentropy()\n",
    "autoenc.build(input_shape=input_tensor_train.shape)\n",
    "\n",
    "\n",
    "# input_tensor_train.shape, autoenc(input_tensor_train).shape # ne pas décommenter si gros gros tenseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 5s 80ms/step - loss: 11497.9980 - accuracy: 0.0131 - val_loss: 10581.5664 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 11475.7627 - accuracy: 0.0119 - val_loss: 10524.3496 - val_accuracy: 0.0522\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 11414.9609 - accuracy: 0.0409 - val_loss: 10487.9922 - val_accuracy: 0.0635\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 11386.8486 - accuracy: 0.0869 - val_loss: 10464.8223 - val_accuracy: 0.0748\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 11361.1045 - accuracy: 0.0756 - val_loss: 10440.2812 - val_accuracy: 0.1497\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 11333.8682 - accuracy: 0.1790 - val_loss: 10410.1396 - val_accuracy: 0.1791\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 11285.0527 - accuracy: 0.1688 - val_loss: 10343.3857 - val_accuracy: 0.1338\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 11210.4844 - accuracy: 0.1489 - val_loss: 10296.1367 - val_accuracy: 0.1111\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 11134.4795 - accuracy: 0.1426 - val_loss: 10244.7588 - val_accuracy: 0.0884\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 11062.2715 - accuracy: 0.1205 - val_loss: 10199.1211 - val_accuracy: 0.0907\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 10989.5996 - accuracy: 0.1045 - val_loss: 10156.1406 - val_accuracy: 0.0748\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 10921.0762 - accuracy: 0.0807 - val_loss: 10112.7842 - val_accuracy: 0.0385\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 10858.1641 - accuracy: 0.0477 - val_loss: 10073.9160 - val_accuracy: 0.0204\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 10805.6875 - accuracy: 0.0312 - val_loss: 10037.2188 - val_accuracy: 0.0113\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 10758.7012 - accuracy: 0.0165 - val_loss: 10004.5000 - val_accuracy: 0.0159\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 10716.0156 - accuracy: 0.0165 - val_loss: 9971.0840 - val_accuracy: 0.0136\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 10674.4326 - accuracy: 0.0188 - val_loss: 9938.4834 - val_accuracy: 0.0159\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 10635.3564 - accuracy: 0.0227 - val_loss: 9905.5342 - val_accuracy: 0.0181\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 10597.7559 - accuracy: 0.0273 - val_loss: 9874.9346 - val_accuracy: 0.0113\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 10561.7988 - accuracy: 0.0284 - val_loss: 9846.0020 - val_accuracy: 0.0091\n"
     ]
    }
   ],
   "source": [
    "history = autoenc.fit(input_tensor_train,target_tensor_train,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(input_tensor_val,target_tensor_val),\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_phrase = [phrasesSpacy[0]]\n",
    "l = tokenizer.texts_to_sequences(dummy_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ll in l:\n",
    "    ll += (max_length-len(ll))*[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoenc.encoder\n",
    "decoder = autoenc.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 128])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(np.asarray(l))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 347, 128]), TensorShape([1, 128]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1,res2 = encoder(np.asarray(l))\n",
    "res1.shape,res2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 347), dtype=float32, numpy=\n",
       "array([[ 1.24931297e+01,  1.17034790e+02,  1.81203403e+01,\n",
       "         4.34330902e+01,  1.57216583e+02,  4.04203529e+01,\n",
       "         1.01612442e+02,  1.99001255e+01,  1.54140594e+02,\n",
       "         2.25662346e+01,  2.13317719e+01,  4.21040764e+01,\n",
       "         4.36036263e+01,  1.63316727e+01,  4.84043121e+01,\n",
       "         2.13577805e+01,  4.03895607e+01,  1.57290833e+02,\n",
       "         2.07951794e+01,  3.60457077e+01,  1.09792007e+02,\n",
       "         1.85135059e+01,  2.10808849e+01,  6.79013443e+01,\n",
       "         2.70839386e+01,  7.38018799e+01,  1.99942074e+01,\n",
       "         1.73816223e+01,  8.45525436e+01,  1.81085663e+01,\n",
       "         2.21186123e+01,  5.04311180e+01,  7.87296829e+01,\n",
       "         2.17105103e+01,  3.94052162e+01,  1.08688309e+02,\n",
       "         1.86318760e+01,  1.57138000e+02,  1.90021553e+01,\n",
       "         1.47965408e+02,  4.56300049e+01,  1.77236004e+01,\n",
       "         4.00220032e+01,  1.26758316e+02,  2.00959606e+01,\n",
       "         1.56864731e+02,  2.57568913e+01,  6.34595795e+01,\n",
       "         1.96296730e+01,  2.15558014e+01,  4.28631554e+01,\n",
       "         4.36841698e+01,  1.63752575e+01,  4.84447250e+01,\n",
       "         2.13750019e+01,  1.57111542e+02,  6.13679581e+01,\n",
       "         1.87528801e+01,  1.56944000e+02,  1.57367950e+02,\n",
       "         2.08112164e+01,  9.58671665e+00,  5.04499292e+00,\n",
       "         6.96279602e+01,  1.57270798e+02,  3.69249649e+01,\n",
       "         1.57288376e+02,  3.92203331e-02,  3.80762434e+00,\n",
       "         2.23785877e+00, -7.90321350e-01, -3.11769891e+00,\n",
       "        -3.81867003e+00, -4.00646400e+00, -2.95810533e+00,\n",
       "        -1.61497045e+00, -1.42124629e+00, -1.29712868e+00,\n",
       "        -1.21593118e+00, -1.17795420e+00, -1.16310191e+00,\n",
       "        -1.15543318e+00, -1.14715004e+00, -1.13565207e+00,\n",
       "        -1.12073755e+00, -1.10304260e+00, -1.08339047e+00,\n",
       "        -1.06251645e+00, -1.04101324e+00, -1.01933908e+00,\n",
       "        -9.97824907e-01, -9.76714373e-01, -9.56188440e-01,\n",
       "        -9.36363935e-01, -9.17326689e-01, -8.99132729e-01,\n",
       "        -8.81806374e-01, -8.65369320e-01, -8.49824190e-01,\n",
       "        -8.35160494e-01, -8.21365118e-01, -8.08417559e-01,\n",
       "        -7.96294451e-01, -7.84970045e-01, -7.74411917e-01,\n",
       "        -7.64592648e-01, -7.55479336e-01, -7.47043371e-01,\n",
       "        -7.39249945e-01, -7.32070446e-01, -7.25471497e-01,\n",
       "        -7.19426394e-01, -7.13902473e-01, -7.08874464e-01,\n",
       "        -7.04314947e-01, -7.00196981e-01, -6.96493387e-01,\n",
       "        -6.93184376e-01, -6.90241098e-01, -6.87646866e-01,\n",
       "        -6.85377598e-01, -6.83416605e-01, -6.81741476e-01,\n",
       "        -6.80335283e-01, -6.79183960e-01, -6.78268671e-01,\n",
       "        -6.77575588e-01, -6.77086353e-01, -6.76793337e-01,\n",
       "        -6.76679611e-01, -6.76735163e-01, -6.76950693e-01,\n",
       "        -6.77312851e-01, -6.77809477e-01, -6.78434610e-01,\n",
       "        -6.79178715e-01, -6.80031300e-01, -6.80988789e-01,\n",
       "        -6.82038784e-01, -6.83178663e-01, -6.84396267e-01,\n",
       "        -6.85691595e-01, -6.87055826e-01, -6.88483953e-01,\n",
       "        -6.89969778e-01, -6.91509247e-01, -6.93099737e-01,\n",
       "        -6.94731712e-01, -6.96407080e-01, -6.98119640e-01,\n",
       "        -6.99863672e-01, -7.01642513e-01, -7.03443766e-01,\n",
       "        -7.05272675e-01, -7.07118750e-01, -7.08983421e-01,\n",
       "        -7.10869312e-01, -7.12763548e-01, -7.14670420e-01,\n",
       "        -7.16587782e-01, -7.18510628e-01, -7.20440626e-01,\n",
       "        -7.22373009e-01, -7.24309921e-01, -7.26245165e-01,\n",
       "        -7.28179216e-01, -7.30110884e-01, -7.32040882e-01,\n",
       "        -7.33963966e-01, -7.35879898e-01, -7.37791300e-01,\n",
       "        -7.39693165e-01, -7.41585732e-01, -7.43465662e-01,\n",
       "        -7.45334864e-01, -7.47196198e-01, -7.49039888e-01,\n",
       "        -7.50871181e-01, -7.52690315e-01, -7.54490852e-01,\n",
       "        -7.56275654e-01, -7.58048058e-01, -7.59799480e-01,\n",
       "        -7.61535645e-01, -7.63252974e-01, -7.64952183e-01,\n",
       "        -7.66631842e-01, -7.68292427e-01, -7.69932508e-01,\n",
       "        -7.71552324e-01, -7.73150444e-01, -7.74727821e-01,\n",
       "        -7.76286364e-01, -7.77821779e-01, -7.79334784e-01,\n",
       "        -7.80825138e-01, -7.82294273e-01, -7.83737421e-01,\n",
       "        -7.85158396e-01, -7.86556721e-01, -7.87932634e-01,\n",
       "        -7.89286137e-01, -7.90609598e-01, -7.91913986e-01,\n",
       "        -7.93190956e-01, -7.94444323e-01, -7.95673847e-01,\n",
       "        -7.96877146e-01, -7.98056126e-01, -7.99213171e-01,\n",
       "        -8.00341606e-01, -8.01444530e-01, -8.02525282e-01,\n",
       "        -8.03576469e-01, -8.04604292e-01, -8.05605173e-01,\n",
       "        -8.06581259e-01, -8.07531834e-01, -8.08457613e-01,\n",
       "        -8.09353590e-01, -8.10227394e-01, -8.11074734e-01,\n",
       "        -8.11893225e-01, -8.12688828e-01, -8.13457727e-01,\n",
       "        -8.14200401e-01, -8.14914703e-01, -8.15607071e-01,\n",
       "        -8.16270828e-01, -8.16909313e-01, -8.17521572e-01,\n",
       "        -8.18108320e-01, -8.18669081e-01, -8.19202900e-01,\n",
       "        -8.19708586e-01, -8.20194960e-01, -8.20650578e-01,\n",
       "        -8.21080685e-01, -8.21485043e-01, -8.21865559e-01,\n",
       "        -8.22216749e-01, -8.22544813e-01, -8.22846889e-01,\n",
       "        -8.23123455e-01, -8.23376656e-01, -8.23601246e-01,\n",
       "        -8.23802233e-01, -8.23978186e-01, -8.24129820e-01,\n",
       "        -8.24252844e-01, -8.24353933e-01, -8.24429035e-01,\n",
       "        -8.24480295e-01, -8.24510098e-01, -8.24510098e-01,\n",
       "        -8.24488163e-01, -8.24438810e-01, -8.24369431e-01,\n",
       "        -8.24275732e-01, -8.24158192e-01, -8.24015141e-01,\n",
       "        -8.23848963e-01, -8.23657751e-01, -8.23442936e-01,\n",
       "        -8.23206186e-01, -8.22947025e-01, -8.22664738e-01,\n",
       "        -8.22361469e-01, -8.22031736e-01, -8.21682692e-01,\n",
       "        -8.21307182e-01, -8.20912361e-01, -8.20495129e-01,\n",
       "        -8.20055008e-01, -8.19595098e-01, -8.19111347e-01,\n",
       "        -8.18607807e-01, -8.18082809e-01, -8.17535162e-01,\n",
       "        -8.16967010e-01, -8.16378832e-01, -8.15769196e-01,\n",
       "        -8.15141439e-01, -8.14491987e-01, -8.13824654e-01,\n",
       "        -8.13133001e-01, -8.12424421e-01, -8.11696768e-01,\n",
       "        -8.10950756e-01, -8.10184717e-01, -8.09399128e-01,\n",
       "        -8.08593750e-01, -8.07772875e-01, -8.06931496e-01,\n",
       "        -8.06072712e-01, -8.05196285e-01, -8.04301500e-01,\n",
       "        -8.03391695e-01, -8.02462101e-01, -8.01514864e-01,\n",
       "        -8.00553799e-01, -7.99573898e-01, -7.98580408e-01,\n",
       "        -7.97570229e-01, -7.96540737e-01, -7.95499802e-01,\n",
       "        -7.94439554e-01, -7.93366671e-01, -7.92280674e-01,\n",
       "        -7.91176081e-01, -7.90060043e-01, -7.88928986e-01,\n",
       "        -7.87782431e-01, -7.86623240e-01, -7.85450220e-01,\n",
       "        -7.84262180e-01, -7.83065557e-01, -7.81852722e-01,\n",
       "        -7.80628204e-01, -7.79388666e-01, -7.78142452e-01,\n",
       "        -7.76881456e-01, -7.75607824e-01, -7.74324656e-01,\n",
       "        -7.73033381e-01, -7.71724463e-01, -7.70408154e-01,\n",
       "        -7.69079924e-01, -7.67743349e-01, -7.66397476e-01,\n",
       "        -7.65043497e-01, -7.63677120e-01, -7.62305260e-01,\n",
       "        -7.60921478e-01, -7.59530544e-01, -7.58128166e-01,\n",
       "        -7.56721497e-01, -7.55306959e-01, -7.53882885e-01,\n",
       "        -7.52453804e-01, -7.51016378e-01, -7.49573231e-01,\n",
       "        -7.48125553e-01, -7.46665239e-01, -7.45208263e-01,\n",
       "        -7.43739128e-01, -7.42264748e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = decoder(res1,res2)\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8,  131,    1,   59,  860,    4,  102,    6,  175,    9,    3,\n",
       "          25,   46,    1,   43,   10,    4,  861,   16,    4,  102,    1,\n",
       "           3,   77,   12,   90,   16,   12,  104,    1,    5,   42,   88,\n",
       "          10,    4,  102,    1, 1565,    1,  166,   42,   16,    4,  285,\n",
       "           6,  214,   12,   85,    1,    3,   25,   46,    1,   43,   10,\n",
       "         390,   85,    1,  247, 1189,   16,   22,    6,   88, 1190,   18,\n",
       "         615,   13,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0, input_shape=(max_length,)))\n",
    "model.add(LSTM(100, activation='tanh',return_sequences=True))\n",
    "model.add(LSTM(50, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(50, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(100, activation='tanh', return_sequences=True))\n",
    "model.add((Dense(1,activation='tanh')))\n",
    "\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics = [\"accuracy\"]) # losses.MeanSquaredError() losses.CosineSimilarity() tf.keras.losses.CategoricalCrossentropy()\n",
    "model.build(input_shape=input_tensor_train.shape)\n",
    "\n",
    "history = model.fit(input_tensor_train,target_tensor_train,\n",
    "                epochs=3,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(input_tensor_val,target_tensor_val),\n",
    "                verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "networks_seq2seq_nmt.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
